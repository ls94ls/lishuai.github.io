<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  <meta http-equiv="pragma" content="no-cache">
  <meta http-equiv="cache-control" content="no-cache">
  <meta http-equiv="expires" content="0">
  
  <title>ELK-day01 | Hexo</title>
  <meta name="author" content="John Doe">
  
  <meta name="description" content="ELK 副本分片详解什么是分片和副本？123在 Elasticsearch 中，索引被划分为多个 分片（shard），这些分片可以分布在集群中的不同节点上，从而实现数据的分散存储和并行处理。每个分片就是一个 Lucene 索引，可以独立地被索引和搜索。副本（replica） 则是分片的一个完整副本，用于提高数据的可靠性和可用性。如果主分片所在的节点发生故障，副本可以接替主分片的角色，保证数据的连续性

为什么需要分片和副本？123-提高性能：将数据分散到多个分片上，可以并行处理查询请求，提高查询性能。-提高可用性：副本可以提供数据冗余，防止数据丢失。如果一个分片所在的节点发生故障，副本可以接替主分片的角色。-扩展性：通过增加节点，可以增加分片数量，从而提高索引容量。

副本分片的主要目的12345副本分片的主要目的就是为了故障转移，如果持有主分片的节点挂掉了，一个副本分片就会晋升为主分片的角色。在索引写入时，副本分片做着与主分片相同的工作。新文档首先被索引进主分片然后再同步到其它所有的副本分片。增加副本数并不会增加索引容量。无论如何，副本分片可以服务于读请求，如果你的索引也如常见的那样是偏向查询使用的，那你可以通过增加副本的数目来提升查询性能，但也要为此，增加额外的硬件资源。

Elasticsearch内部分片处理机制详解逆向索引12345678910与传统的数据库不同，在Elasticsearch中，每个字段里面的每个单词都是可以被搜索的。如teacher：“zls，bgx，lidao，oldboy，alex”我们在搜索关键字oldboy时，所有包含oldboy的文档都会被匹配到Elasticsearch的这个特性也叫做全文搜索为了支持这个特性，Elasticsearch中会维护一个叫做“invertedindex”（也叫逆向索引）的表，表内包含了所有文档中出现的所有单词，同时记录了这个单词在哪个文档中出现过。逆向索引里面不止记录了单词与文档的对应关系，它还维护了很多其他有用的数据。如：每个文档一共包含了多少个单词，单词在不同文档中的出现频率，每个文档的长度，所有文档的总长度等等。这些数据用来给搜索结果进行打分，如搜索zls时，那么出现zls这个单词次数最多的文档会被优先返回，因为它匹配的次数最多，和我们的搜索条件关联性最大，因此得分也最多。逆向索引是不可更改的，一旦它被建立了，里面的数据就不会再进行更改。这样做就带来了以下几个好处：1.没有必要给逆向索引加锁，因为不允许被更改，只有读操作，所以就不用考虑多线程导致互斥等问题。2.索引一旦被加载到了缓存中，大部分访问操作都是对内存的读操作，省去了访问磁盘带来的io开销。3.因为逆向索引的不可变性，所有基于该索引而产生的缓存也不需要更改，因为没有数据变更。4.使用逆向索引可以压缩数据，减少磁盘io及对内存的消耗。"> 
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="ELK-day01"/>
  <meta property="og:site_name" content="Hexo"/>

  
    <meta property="og:image" content=""/>
  

  
    <link rel="alternative" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link href="/favicon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/responsive.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/prism.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  
  <!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-70812759-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-70812759-1');
</script>






<meta name="generator" content="Hexo 7.3.0"></head>

 <body>  
  <nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">Hexo</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class=""></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class=""></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class=""></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class=""></i>About
			</a>
		  </li>
		  
		  <li>
			<a href="/atom.xml" title="Subscribe me.">
			  <i class=""></i>RSS
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 


	
		<div class="page-header">
			<h1> ELK-day01</h1>
		</div>
	



<div class="row post">
	<!-- cols -->
	
	<div id="top_meta"></div>
	<div class="col-md-9">
	

	<!-- content -->
	<div class="mypage">		
	  		

	  <h1 id="ELK-副本分片详解"><a href="#ELK-副本分片详解" class="headerlink" title="ELK 副本分片详解"></a>ELK 副本分片详解</h1><h2 id="什么是分片和副本？"><a href="#什么是分片和副本？" class="headerlink" title="什么是分片和副本？"></a>什么是分片和副本？</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">在 Elasticsearch 中，索引被划分为多个 分片（shard），这些分片可以分布在集群中的不同节点上，从而实现数据的分散存储和并行处理。每个分片就是一个 Lucene 索引，可以独立地被索引和搜索。</span><br><span class="line"></span><br><span class="line">副本（replica） 则是分片的一个完整副本，用于提高数据的可靠性和可用性。如果主分片所在的节点发生故障，副本可以接替主分片的角色，保证数据的连续性</span><br></pre></td></tr></table></figure>

<h2 id="为什么需要分片和副本？"><a href="#为什么需要分片和副本？" class="headerlink" title="为什么需要分片和副本？"></a>为什么需要分片和副本？</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">-提高性能：将数据分散到多个分片上，可以并行处理查询请求，提高查询性能。</span><br><span class="line">-提高可用性：副本可以提供数据冗余，防止数据丢失。如果一个分片所在的节点发生故障，副本可以接替主分片的角色。</span><br><span class="line">-扩展性：通过增加节点，可以增加分片数量，从而提高索引容量。</span><br></pre></td></tr></table></figure>

<h2 id="副本分片的主要目的"><a href="#副本分片的主要目的" class="headerlink" title="副本分片的主要目的"></a>副本分片的主要目的</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">副本分片的主要目的就是为了故障转移，如果持有主分片的节点挂掉了，一个副本分片就会晋升为主分片的角色。</span><br><span class="line"></span><br><span class="line">在索引写入时，副本分片做着与主分片相同的工作。新文档首先被索引进主分片然后再同步到其它所有的副本分片。增加副本数并不会增加索引容量。</span><br><span class="line"></span><br><span class="line">无论如何，副本分片可以服务于读请求，如果你的索引也如常见的那样是偏向查询使用的，那你可以通过增加副本的数目来提升查询性能，但也要为此，增加额外的硬件资源。</span><br></pre></td></tr></table></figure>

<h2 id="Elasticsearch内部分片处理机制详解"><a href="#Elasticsearch内部分片处理机制详解" class="headerlink" title="Elasticsearch内部分片处理机制详解"></a>Elasticsearch内部分片处理机制详解</h2><h3 id="逆向索引"><a href="#逆向索引" class="headerlink" title="逆向索引"></a>逆向索引</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">与传统的数据库不同，在Elasticsearch中，每个字段里面的每个单词都是可以被搜索的。如teacher：“zls，bgx，lidao，oldboy，alex”我们在搜索关键字oldboy时，所有包含oldboy的文档都会被匹配到Elasticsearch的这个特性也叫做全文搜索</span><br><span class="line">为了支持这个特性，Elasticsearch中会维护一个叫做“invertedindex”（也叫逆向索引）的表，表内包含了所有文档中出现的所有单词，同时记录了这个单词在哪个文档中出现过。</span><br><span class="line"></span><br><span class="line">逆向索引里面不止记录了单词与文档的对应关系，它还维护了很多其他有用的数据。如：每个文档一共包含了多少个单词，单词在不同文档中的出现频率，每个文档的长度，所有文档的总长度等等。这些数据用来给搜索结果进行打分，如搜索zls时，那么出现zls这个单词次数最多的文档会被优先返回，因为它匹配的次数最多，和我们的搜索条件关联性最大，因此得分也最多。</span><br><span class="line"></span><br><span class="line">逆向索引是不可更改的，一旦它被建立了，里面的数据就不会再进行更改。这样做就带来了以下几个好处：</span><br><span class="line">1.没有必要给逆向索引加锁，因为不允许被更改，只有读操作，所以就不用考虑多线程导致互斥等问题。</span><br><span class="line">2.索引一旦被加载到了缓存中，大部分访问操作都是对内存的读操作，省去了访问磁盘带来的io开销。</span><br><span class="line">3.因为逆向索引的不可变性，所有基于该索引而产生的缓存也不需要更改，因为没有数据变更。</span><br><span class="line">4.使用逆向索引可以压缩数据，减少磁盘io及对内存的消耗。</span><br></pre></td></tr></table></figure>

<p><img src="C:\Users\kazzy\AppData\Roaming\Typora\typora-user-images\image-20241106173708029.png" alt="image-20241106173708029"></p>
<h3 id="Segment"><a href="#Segment" class="headerlink" title="Segment"></a>Segment</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">既然逆向索引是不可更改的，那么如何添加新的数据，删除数据以及更新数据？为了解决这个问题，lucene将一个大的逆向索引拆分成了多个小的段segment。每个segment本质上就是一个逆向索引。在lucene中，同时还会维护一个文件commit point，用来记录当前所有可用的segment，当我们在这个commit point上进行搜索时，就相当于在它下面的segment中进行搜索，每个segment返回自己的搜索结果，然后进行汇总返回给用户。</span><br><span class="line"></span><br><span class="line">引入了segment和commit point的概念之后，数据的更新流程如下图：</span><br><span class="line">Lucene处理新增文档的流程</span><br><span class="line">1.新增的文档首先会被存放在内存的缓存中</span><br><span class="line">2.当文档数足够多或者到达一定时间点时，就会对缓存进行commit</span><br><span class="line">	a. 生成一个新的segment，并写入磁盘</span><br><span class="line">	b. 生成一个新的commit point，记录当前所有可用的segment</span><br><span class="line">	c. 等待所有数据都已写入磁盘</span><br><span class="line">3.打开新增的segment，这样我们就可以对新增的文档进行搜索了</span><br><span class="line">4.清空缓存，准备接收新的文档</span><br></pre></td></tr></table></figure>

<p><img src="C:\Users\kazzy\AppData\Roaming\Typora\typora-user-images\image-20241106174717085.png" alt="image-20241106174717085"></p>
<h3 id="为什么要考虑副本分片数量？"><a href="#为什么要考虑副本分片数量？" class="headerlink" title="为什么要考虑副本分片数量？"></a>为什么要考虑副本分片数量？</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">大多数ElasticSearch用户在创建索引时通用会考虑一个重要问题是:我需要创建多少个分片?</span><br><span class="line">分片分配是个很重要的概念, 很多用户对如何分片都有所疑惑, 当然是为了让分配更合理. 在生产环境中,随着数据集的增长, 不合理的分配策略可能会给系统的扩展带来严重的问题。</span><br><span class="line">同时, 这方面的文档介绍也非常少。很多用户只想要明确的答案而不仅仅一个数字范围, 甚至都不关心随意的设置可能带来的问题。</span><br><span class="line"></span><br><span class="line">首先，我们需要了解ES中以下几个名词，是做什么的：</span><br><span class="line">-集群(cluster):由一个或多个节点组成, 并通过集群名称与其他集群进行区分</span><br><span class="line">-节点(node):单个ElasticSearch实例. 通常一个节点运行在一个隔离的容器或虚拟机中</span><br><span class="line">-索引(index):在ES中, 索引是一组文档的集合（就是我们所说的一个日志）</span><br><span class="line">-分片(shard):因为ES是个分布式的搜索引擎, 所以索引通常都会分解成不同部分, 而这些分布在不同节点的数据就是分片. ES自动管理和组织分片, 并在必要的时候对分片数据进行再平衡分配, 所以用户基本上不用担心分片的处理细节，一个分片默认最大文档数量是20亿.</span><br><span class="line">-副本(replica):ES默认为一个索引创建5个主分片, 并分别为其创建一个副本分片. 也就是说每个索引都由5个主分片成本, 而每个主分片都相应的有一个copy.</span><br><span class="line"></span><br><span class="line">对于分布式搜索引擎来说, 分片及副本的分配将是高可用及快速搜索响应的设计核心.主分片与副本都能处理查询请求, 它们的唯一区别在于只有主分片才能处理索引请求.</span><br><span class="line"></span><br><span class="line">谨慎分片</span><br><span class="line">副本对搜索性能非常重要, 同时用户也可在任何时候添加或删除副本。额外的副本能给你带来更大的容量, 更高的呑吐能力及更强的故障恢复能力。</span><br><span class="line">当在ElasticSearch集群中配置好你的索引后, 你要明白在集群运行中你无法调整分片设置。既便以后你发现需要调整分片数量, 你也只能新建创建并对数据进行重新索引(reindex)(虽然reindex会比较耗时, 但至少能保证你不会停机)。</span><br><span class="line"></span><br><span class="line">主分片的配置与硬盘分区很类似, 在对一块空的硬盘空间进行分区时, 会要求用户先进行数据备份, 然后配置新的分区, 最后把数据写到新的分区上。</span><br><span class="line"></span><br><span class="line">在分片时，主要考虑数据集的增长趋势,一定要做到不要过度分片,并不是分片越多越好,从ES社区用户对这个热门主题(分片配置)的分享数据来看, 用户可能认为过度分配是个绝对安全的策略(这里讲的过度分配是指对特定数据集, 为每个索引分配了超出当前数据量(文档数)所需要的分片数)。</span><br><span class="line"></span><br><span class="line">稍有富余是好的, 但过度分配分片却是大错特错. 具体定义多少分片很难有定论, 取决于用户的数据量和使用方式. 100个分片, 即便很少使用也可能是好的;而2个分片, 即便使用非常频繁, 也可能是多余的</span><br><span class="line"></span><br><span class="line">我们要熟知以下几点内容：</span><br><span class="line">1.每分配一个分片，都会有额外的成本。</span><br><span class="line">2.每个分片本质上就是一个Lucene索引，因此会消耗相应的文件句柄，内存和CPU资源。</span><br><span class="line">3.每个搜索请求会调度到索引的每个分片中。如果分片分散在不同的节点倒是问题不太。但当分片开始竞争相同的硬件资源时，性能便会逐步下降。</span><br><span class="line">4.ES使用词频统计来计算相关性。当然这些统计也会分配到各个分片上。如果在大量分片上只维护了很少的数据，则将导致最终的文档相关性较差。</span><br></pre></td></tr></table></figure>

<p><img src="C:\Users\kazzy\AppData\Roaming\Typora\typora-user-images\image-20241106181327097.png" alt="image-20241106181327097"></p>
<h3 id="规模数据集场景"><a href="#规模数据集场景" class="headerlink" title="规模数据集场景"></a>规模数据集场景</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">如果真的担心数据的快速增长, 我们建议你多关心这条限制: ElasticSearch推荐的最大JVM堆空间是30~32G, 所以把你的分片最大容量限制为30GB, 然后再对分片数量做合理估算. 例如, 你认为你的数据能达到200GB, 我们推荐你最多分配7到8个分片.</span><br><span class="line"></span><br><span class="line">总之, 不要现在就为你可能在三年后才能达到的10TB数据做过多分配. 如果真到那一天, 你也会很早感知到性能变化的.</span><br><span class="line"></span><br><span class="line">尽管本部分并未详细讨论副本分片, 但我们推荐你保持适度的副本数并随时可做相应的增加. 如果你正在部署一个新的环境, 也许你可以参考我们的基于副本的集群的设计.这个集群有三个节点组成, 每个分片只分配了副本. 不过随着需求变化, 你可以轻易的调整副本数量.</span><br><span class="line"></span><br><span class="line">对大数据集, 我们非常鼓励你为索引多分配些分片--当然也要在合理范围内. 上面讲到的每个分片最好不超过30GB的原则依然使用.</span><br><span class="line"></span><br><span class="line">不过, 你最好还是能描述出每个节点上只放一个索引分片的必要性. 在开始阶段, 一个好的方案是根据你的节点数量按照1.5~3倍的原则来创建分片. 例如：如果你有3个节点, 则推荐你创建的分片数最多不超过9(3x3)个.</span><br><span class="line"></span><br><span class="line">随着数据量的增加,如果你通过集群状态API发现了问题,或者遭遇了性能退化,则只需要增加额外的节点即可. ES会自动帮你完成分片在不同节点上的分布平衡.</span><br><span class="line"></span><br><span class="line">再强调一次, 虽然这里我们暂未涉及副本节点的介绍, 但上面的指导原则依然使用: 是否有必要在每个节点上只分配一个索引的分片. 另外, 如果给每个分片分配1个副本, 你所需的节点数将加倍. 如果需要为每个分片分配2个副本, 则需要3倍的节点数.</span><br></pre></td></tr></table></figure>

<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">再次声明, 数据分片也是要有相应资源消耗,并且需要持续投入.</span><br><span class="line"></span><br><span class="line">当索引拥有较多分片时, 为了组装查询结果, ES必须单独查询每个分片(当然并行的方式)并对结果进行合并. 所以高性能IO设备(SSDs)和多核处理器无疑对分片性能会有巨大帮助. 尽管如此, 你还是要多关心数据本身的大小,更新频率以及未来的状态. 在分片分配上并没有绝对的答案, 只希望大家能从本博客中受益.</span><br></pre></td></tr></table></figure>

<h1 id="分片操作实战"><a href="#分片操作实战" class="headerlink" title="分片操作实战"></a>分片操作实战</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">分片</span><br><span class="line">正如上文中提到，创建分片，不超过3倍，在本课程中，我们有两个节点，所以我们可以设置6个分片</span><br><span class="line"></span><br><span class="line"><span class="comment">#在每个节点上执行，分配1个副本6个分片</span></span><br><span class="line">[root@elkstack01 ~]# curl -XPUT 10.0.0.81:9200/_template/my_template -d<span class="string">&#x27;</span></span><br><span class="line"><span class="string">&#123; &quot;template&quot;: &quot;*&quot;,</span></span><br><span class="line"><span class="string">	&quot;settings&quot;: &#123;</span></span><br><span class="line"><span class="string">	&quot;index&quot;: &#123;</span></span><br><span class="line"><span class="string">	&quot;number_of_shards&quot;: 6,</span></span><br><span class="line"><span class="string">	&quot;number_of_replicas&quot;: 1</span></span><br><span class="line"><span class="string">		&#125;</span></span><br><span class="line"><span class="string">	&#125;</span></span><br><span class="line"><span class="string">&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#返回结果为true，分片成功</span></span><br><span class="line">&#123;<span class="string">&quot;acknowledged&quot;</span>:<span class="literal">true</span>&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h1 id="健康值"><a href="#健康值" class="headerlink" title="健康值"></a>健康值</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">绿色:正常的健康集群(没有分片丢失)</span><br><span class="line">黄色:非常准的健康颜色(有分片的丢失)</span><br><span class="line">红色:非正常的健康颜色(副本的主分片和副分片全部丢失)</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">集群健康值检查脚本</span><br><span class="line"><span class="comment">#编写python脚本</span></span><br><span class="line">[root@elkstack01 ~]# vim es_cluster_status.py</span><br><span class="line"><span class="comment">#!/usr/bin/env python</span></span><br><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="comment">#Author:_DriverZeng_</span></span><br><span class="line"><span class="comment">#Date:2017.02.12</span></span><br><span class="line"></span><br><span class="line">import smtplib</span><br><span class="line">from email.mime.text import MIMEText</span><br><span class="line">from email.utils import formataddr</span><br><span class="line">import subprocess</span><br><span class="line">body = <span class="string">&quot;&quot;</span></span><br><span class="line"><span class="literal">false</span> = <span class="string">&quot;false&quot;</span></span><br><span class="line">clusterip = <span class="string">&quot;10.0.0.51&quot;</span></span><br><span class="line">obj = subprocess.Popen((&quot;curl -sXGET</span><br><span class="line">http://&quot;+clusterip+&quot;:<span class="number">9200</span>/_cluster/health?pretty=true&quot;),shell=True,</span><br><span class="line">stdout=subprocess.PIPE)</span><br><span class="line">data = obj.stdout.read()</span><br><span class="line">data1 = eval(data)</span><br><span class="line">status = data1.get(&quot;status&quot;)</span><br><span class="line">if status == &quot;green&quot;:</span><br><span class="line">	print &quot;\<span class="number">033</span>[<span class="number">1</span>;<span class="number">32</span>m 集群运行正常 \<span class="number">033</span>[<span class="number">0</span>m&quot;</span><br><span class="line">elif status == &quot;yellow&quot;:</span><br><span class="line">	print &quot;\<span class="number">033</span>[<span class="number">1</span>;<span class="number">33</span>m 副本分片丢失 \<span class="number">033</span>[<span class="number">0</span>m&quot;</span><br><span class="line">else:</span><br><span class="line">	print &quot;\<span class="number">033</span>[<span class="number">1</span>;<span class="number">31</span>m 主分片丢失 \<span class="number">033</span>[<span class="number">0</span>m&quot;</span><br><span class="line"></span><br><span class="line">#执行结果如下</span><br><span class="line">[root@elkstack01 ~]# python es_cluster_status.py</span><br><span class="line">集群运行正常</span><br></pre></td></tr></table></figure>

<h1 id="Logstash入门-部署与测试"><a href="#Logstash入门-部署与测试" class="headerlink" title="Logstash入门-部署与测试"></a>Logstash入门-部署与测试</h1><p><img src="C:\Users\kazzy\AppData\Roaming\Typora\typora-user-images\image-20241107090506422.png" alt="image-20241107090506422"></p>
<h2 id="logstash的部署"><a href="#logstash的部署" class="headerlink" title="logstash的部署"></a>logstash的部署</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装jdk环境</span></span><br><span class="line">yum install -y java</span><br><span class="line"></span><br><span class="line"><span class="comment"># 部署logstash</span></span><br><span class="line">logstash-5.3.0.rpm</span><br><span class="line"></span><br><span class="line"><span class="comment"># 下载rpm包</span></span><br><span class="line">yum localinstall logstash-5.3.0.rpm -y</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将 Logstash 的可执行文件路径添加到系统的环境变量 PATH 中</span></span><br><span class="line">[root@logstash ~]# <span class="built_in">cat</span> /etc/profile.d/logstash.sh </span><br><span class="line"><span class="built_in">export</span> PATH=<span class="string">&quot;/usr/share/logstash/bin/:<span class="variable">$PATH</span>&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#source /etc/profile命令用于重新读取并执行/etc/profile文件中的配置。这个命令通常在修改了/etc/profile文件后，想要立即生效这些修改时使用。</span></span><br><span class="line"><span class="built_in">source</span> /etc/profile </span><br></pre></td></tr></table></figure>

<h2 id="Logstash输入输出插件测试"><a href="#Logstash输入输出插件测试" class="headerlink" title="Logstash输入输出插件测试"></a>Logstash输入输出插件测试</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 测试内容</span></span><br><span class="line">logstash -e <span class="string">&#x27;input&#123;stdin&#123;&#125;&#125; output&#123;stdout&#123;&#125;&#125;&#x27;</span></span><br><span class="line">xxx 							  <span class="comment"># 标准输入</span></span><br><span class="line">2024-11-06T12:20:13.654Z es03 xxx <span class="comment"># 标准输出</span></span><br><span class="line">yyy</span><br><span class="line">2024-11-06T12:20:21.718Z es03 yyy</span><br><span class="line">xxx</span><br><span class="line">2024-11-06T12:20:26.212Z es03 xxx</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="logstash标准输入输出到文件"><a href="#logstash标准输入输出到文件" class="headerlink" title="logstash标准输入输出到文件"></a>logstash标准输入输出到文件</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将你从命令行输入的数据实时地写入到 /tmp/test.txt 文件中。</span></span><br><span class="line">logstash -e <span class="string">&#x27;input&#123;stdin&#123;&#125;&#125; output&#123;file&#123;path =&gt; &quot;/tmp/test.txt&quot;&#125;&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<h2 id="logstash标准输入输出到es中"><a href="#logstash标准输入输出到es中" class="headerlink" title="logstash标准输入输出到es中"></a>logstash标准输入输出到es中</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 将你从命令行输入的数据实时地发送到 Elasticsearch 中，并存储在每天新建的索引test_stdin_YYYY.MM.dd,(YYYY.MM.dd为年月日，该命令不需要输入具体的日期)</span></span><br><span class="line">logstash -e <span class="string">&#x27;input&#123;stdin&#123;&#125;&#125; output&#123;elasticsearch&#123;hosts =&gt; [&quot;10.0.0.81:9200&quot;] index =&gt; &quot;test_stdin_%&#123;+YYYY.MM.dd&#125;&quot; &#125;&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<h1 id="练习"><a href="#练习" class="headerlink" title="练习"></a>练习</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">1.收集系统日志到es中 index名字是message_xxxx.xx.dd</span><br><span class="line">2.收集nginx访问日志&amp;错误日志到es中 index名字是nginx_err_xxxx.mm.dd &amp; nginx_access_xxxx.mm.dd</span><br><span class="line"></span><br><span class="line">logstash -e <span class="string">&#x27;input&#123;file&#123;path =&gt; &quot;/var/log/messages&quot;&#125;&#125; output&#123;elasticsearch&#123;hosts =&gt; [&quot;10.0.0.81:9200&quot;] index =&gt; &quot;messages_%&#123;+YYYY.MM.dd&#125;&quot;&#125;&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line">logstash -e <span class="string">&#x27;input&#123;file&#123;path =&gt; &quot;/var/log/nginx/access.log&quot;&#125;&#125; output&#123;elasticsearch&#123;hosts =&gt; [&quot;10.0.0.81:9200&quot;] index =&gt; &quot;nginx_access_%&#123;+YYYY.MM.dd&#125;&quot;&#125;&#125;&#x27;</span></span><br><span class="line"></span><br><span class="line">logstash -e <span class="string">&#x27;input&#123;file&#123;path =&gt; &quot;/var/log/nginx/error.log&quot;&#125;&#125; output&#123;elasticsearch&#123;hosts =&gt; [&quot;10.0.0.81:9200&quot;] index =&gt; &quot;nginx_error_%&#123;+YYYY.MM.dd&#125;&quot;&#125;&#125;&#x27;</span></span><br></pre></td></tr></table></figure>

<p><img src="C:\Users\kazzy\AppData\Roaming\Typora\typora-user-images\image-20241106172038095.png" alt="image-20241106172038095"></p>

	  <div class="article-footer-copyright">

    本博客采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议(CC BY-NC-SA 4.0) 发布.</a>
</div>

	</div>

	
	
	<div>
  	<center>

	<div class="pagination">

    
    
    <a type="button" class="btn btn-default disabled"><i class="fa fa-arrow-circle-o-left"></i>Prev</a>
    

    <a href="/" type="button" class="btn btn-default"><i class="fa fa-home"></i>Home</a>
    
    <a href="/2025/03/06/hello-world/" type="button" class="btn btn-default ">Next<i
                class="fa fa-arrow-circle-o-right"></i></a>
    

    
</div>


    </center>
	</div>
	
	<!-- comment -->
	<!--
<section id="comment">
    <h2 class="title">Comments</h2>

    
</section>

-->
	
	
	
	</div> <!-- col-md-9/col-md-12 -->


	
	<div id="side_meta">
		<div class="col-md-3" id="post_meta"> 

	<!-- date -->
	
	<div class="meta-widget">
	<i class="fa fa-clock-o"></i>
	2025-03-07 
	</div>
	

	<!-- categories -->
    

	<!-- tags -->
		

	<!-- toc -->
	<div class="meta-widget">
	
	</div>
	
    <hr>
	
</div><!-- col-md-3 -->

		

	</div>
	
		

</div><!-- row -->

<!--
 -->



	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  
  &copy; 2025 John Doe's Blog
  
      powered by <a href="http://hexo.io/" target="_blank">Hexo</a>.Theme <a href="https://github.com/Ares-X/hexo-theme-freemind.bithack" target="_blank">freemind.bithack</a>  
</p>
 </footer>
</div> <!-- container-narrow -->
  


  
<a id="gotop" href="#">   
  <span>⬆︎TOP</span>
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>
<script src="/js/search.js"></script> 


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>



   <script type="text/javascript">      
     var search_path = "search.xml";
	 if (search_path.length == 0) {
	 	search_path = "search.xml";
	 }
	 var path = "/" + search_path;
     searchFunc(path, 'local-search-input', 'local-search-result');
   </script>

</body>
   </html>
